{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacks batch 4 - notebook 3\n",
    "\n",
    "This notebook contains filtering steps for the batch 4 genepop file output from populations (see notebook 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering\n"
     ]
    }
   ],
   "source": [
    "cd scripts/PostStacksFiltering/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I edited the file `Input_extraFilters.txt` with the correct arguments and then saved as `Input_extraFilters_b4_5-8.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python genBASH_finalfilters.py Input_extraFilters_b4_5-8.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually removed the unzipping tags / matches files part, because my files are already unzipped and there seems to be a bug switching between directories here (possibly because I have a space in my absolute path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x ./PostStacksFiltering_b4_wgenome.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run at command line\n",
    "./PostStacksFiltering_b4_wgenome.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was having some difficulty getting the script to run, but it was because my Input file was missing an argument, so I edited the base Iput script.\n",
    "\n",
    "I was also having problems with my script because I have to have spaces in the file path for python to read. So I went in and manually added \"\\\" before the spaces. \n",
    "\n",
    "\n",
    "The script ran fine until it hit a discrepancy where a file that should have been called \"CorrectedGenotypes\" for `add_sample_to_genepop.py` was instead named \"CorrectedGenos\" in the code to run `genepop_conversion_corrected.py`. I renamed the file. Since I don't want to run MAF or Missing Value filtering until I see which individuals have too much missing data, I'm just going to run the scripts `add_sample_to_genepop.py` and `transpose.yp` manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering\n"
     ]
    }
   ],
   "source": [
    "cd ../scripts/PostStacksFiltering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding 'sample' as the first column header\r\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/add_sample_to_genepop.py \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome \\\n",
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/transpose.py /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.CorrectedGenotypes_biallelic_edit.genepop \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.CorrectedGenotypes_biallelic_TRANSPOSED.genepop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome\n"
     ]
    }
   ],
   "source": [
    "cd ../batch_4_wgenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing that tranpose worked...\n",
      "['PO010715_02', '0202', '0101', '0101', '0202', '0101', '0101', '0202', '0000', '0101', '0202', '0101', '0202', '0102', '0101', '0101', '0101', '0202', '0101', '0202']\n",
      "\n",
      "\n",
      "You have  33  samples missing > 20% of their data.\n",
      "Samples have been written to an output file\n"
     ]
    }
   ],
   "source": [
    "myfile = open(\"batch_4.CorrectedGenotypes_biallelic_TRANSPOSED.genepop\", \"r\")\n",
    "\n",
    "temp_list =[]\n",
    "\n",
    "for line in myfile:\n",
    "    linelist = line.strip().split()\n",
    "    temp_list.append(linelist)\n",
    "myfile.close()\n",
    "\n",
    "import numpy as np\n",
    "np.asarray(temp_list).T.tolist()\n",
    "genotype_array = np.asarray(temp_list).T.tolist()\n",
    "\n",
    "print \"Testing that tranpose worked...\"\n",
    "print genotype_array[1][0:20]\n",
    "print \"\"\n",
    "print \"\"\n",
    "\n",
    "\n",
    "samples_missing_data = []\n",
    "missing_counts = []\n",
    "missing_percents = []\n",
    "column_numbers = [] #to remove from MAF and Locus filtering\n",
    "\n",
    "for i in range(1, len(genotype_array)):\n",
    "    count = 0\n",
    "    for geno in genotype_array[i]:\n",
    "        if geno == '0000':\n",
    "               count += 1\n",
    "    percent_missing = float(count)/float(len(genotype_array[i]))\n",
    "    if percent_missing > float(0.20): \n",
    "        samples_missing_data.append(genotype_array[i][0])\n",
    "        missing_counts.append(count)\n",
    "        missing_percents.append(percent_missing)\n",
    "        column_numbers.append(str(i))\n",
    "\n",
    "print \"You have \", len(samples_missing_data), \" samples missing > 20% of their data.\"\n",
    "\n",
    "output = open(\"batch_4.pre-filter.Samples_Missing_gt20genos.txt\", \"w\")\n",
    "output.write(\"sample\\tn_missing_genotypes\\tp_missing_genotypes\")\n",
    "\n",
    "for i in range(0,len(samples_missing_data)):\n",
    "    output.write(\"\\n\" + str(samples_missing_data[i]) + \"\\t\" + str(missing_counts[i]) + \"\\t\" + str(missing_percents[i]))\n",
    "output.close()\n",
    "\n",
    "print \"Samples have been written to an output file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So now I want to filter for MAF and for loci with missing data, without including the individuals that are missing >20% of their data (may cause me to throw out loci that should be kept). I'll do this by manually changing the scripts below to exclude counting those samples, but still write them out to the next step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/convert_genepop_to_csv.py \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome \\\n",
    "4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering\n"
     ]
    }
   ],
   "source": [
    "cd ../scripts/PostStacksFiltering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 9 populations.\r\n",
      "These are your populations, with the number of samples in each:\r\n",
      "OrderedDict([('Pohang15', 31), ('Geoje15', 33), ('Namhae15', 16), ('YellowSea16', 24), ('Jukbyeon07', 25), ('JinhaeBay07', 37), ('JinhaeBay08', 43), ('Boryeong07', 22), ('Geoje14', 33)])\r\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/genMAFfiltering.py \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PopMap_L1-4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to remove the following column numbers from the MAF filtering script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['121', '132', '133', '135', '138', '140', '142', '146', '148', '149', '151', '152', '157', '160', '163', '165', '166', '168', '175', '176', '179', '185', '187', '190', '192', '194', '200', '202', '210', '230', '232', '235', '256']\n"
     ]
    }
   ],
   "source": [
    "print column_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/Eleni_filter_by_MinorAlleleFrequency_takeARGS_b4_5-8.py\", line 43, in <module>\r\n",
      "    JinhaeBay07 = stripped_string.split(',')[130:132] + stripped_string.split(',')[134] + stripped_string.split(',')[136:138] + stripped_string.split(',')[139] + stripped_string.split(',')[141] + stripped_string.split(',')[143:146] + stripped_string.split(',')[147] + stripped_string.split(',')[150] + stripped_string.split(',')[153:157] + stripped_string.split(',')[158:160] + stripped_string.split(',')[161:163] + stripped_string.split(',')[164]\r\n",
      "TypeError: can only concatenate list (not \"str\") to list\r\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/Eleni_filter_by_MinorAlleleFrequency_takeARGS_b4_5-8.py \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.CorrectedGenotypes_biallelic_TRANSPOSED.csv \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.MAFfiltering_outputFreqs \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.filteredMAF \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.MAFfiltering_BADgenotypes \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.MAFfiltering_blacklistedMAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To fix this, I made [164] into [164:164]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python /mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering/Eleni_filter_by_MinorAlleleFrequency_takeARGS_b4_5-8.py \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.CorrectedGenotypes_biallelic_TRANSPOSED.csv \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.MAFfiltering_outputFreqs \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.filteredMAF \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.MAFfiltering_BADgenotypes \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.MAFfiltering_blacklistedMAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts/PostStacksFiltering'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 9 populations.\r\n",
      "These are your populations, with the number of samples in each:\r\n",
      "OrderedDict([('Pohang15', 31), ('Geoje15', 33), ('Namhae15', 16), ('YellowSea16', 24), ('Jukbyeon07', 25), ('JinhaeBay07', 37), ('JinhaeBay08', 43), ('Boryeong07', 22), ('Geoje14', 33)])\r\n"
     ]
    }
   ],
   "source": [
    "!python genMissingLoci.py ../PopMap_L1-4.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Again, I removed column numbers from the script that corresponded with the samples missing >20% of their data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 7999 loci\r\n",
      "Number of loci removed: 336\r\n"
     ]
    }
   ],
   "source": [
    "!python FilterLoci_by_MissingValues_b4_5-8.py \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.filteredMAF \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.filteredMAF_filteredLoci \\\n",
    "/mnt/hgfs/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome/batch_4.LociFiltering_blacklistedLoci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "So I end up with a total of **7,663 loci**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "I then went through the final genepop file and removed any individuals with >20% of their genotypes missing. \n",
    "\n",
    "The new filtered genepop: `batch_4.filteredMAF_filteredLoci_filteredIndivids`\n",
    "\n",
    "The genepop with the filtered OUT individuals: `batch_4.filteredMAF_filteredLoci_BADindivids`\n",
    "\n",
    "<br>\n",
    "*see below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/batch_4_wgenome\n"
     ]
    }
   ],
   "source": [
    "cd ../batch_4_wgenome/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing that tranpose worked...\n",
      "['PO010715_02', '0202', '0101', '0202', '0101', '0202', '0000', '0202', '0101', '0202', '0102', '0101', '0101', '0101', '0202', '0101', '0102', '0101', '0202', '0101']\n",
      "\n",
      "\n",
      "You have  30  samples missing > 20% of their data.\n",
      "Samples have been written to an output file\n"
     ]
    }
   ],
   "source": [
    "myfile = open(\"batch_4.filteredMAF_filteredLoci\", \"r\")\n",
    "\n",
    "temp_list =[]\n",
    "\n",
    "for line in myfile:\n",
    "    linelist = line.strip().split(',')\n",
    "    temp_list.append(linelist)\n",
    "myfile.close()\n",
    "\n",
    "import numpy as np\n",
    "np.asarray(temp_list).T.tolist()\n",
    "genotype_array = np.asarray(temp_list).T.tolist()\n",
    "\n",
    "print \"Testing that tranpose worked...\"\n",
    "print genotype_array[1][0:20]\n",
    "print \"\"\n",
    "print \"\"\n",
    "\n",
    "\n",
    "samples_missing_data = []\n",
    "missing_counts = []\n",
    "missing_percents = []\n",
    "column_numbers = [] #to remove from MAF and Locus filtering\n",
    "\n",
    "for i in range(1, len(genotype_array)):\n",
    "    count = 0\n",
    "    for geno in genotype_array[i]:\n",
    "        if geno == '0000':\n",
    "               count += 1\n",
    "    percent_missing = float(count)/float(len(genotype_array[i]))\n",
    "    if percent_missing > float(0.20): \n",
    "        samples_missing_data.append(genotype_array[i][0])\n",
    "        missing_counts.append(count)\n",
    "        missing_percents.append(percent_missing)\n",
    "        column_numbers.append(str(i))\n",
    "\n",
    "print \"You have \", len(samples_missing_data), \" samples missing > 20% of their data.\"\n",
    "\n",
    "output = open(\"batch_4.post-filter.Samples_Missing_gt20genos.txt\", \"w\")\n",
    "output.write(\"sample\\tn_missing_genotypes\\tp_missing_genotypes\")\n",
    "\n",
    "for i in range(0,len(samples_missing_data)):\n",
    "    output.write(\"\\n\" + str(samples_missing_data[i]) + \"\\t\" + str(missing_counts[i]) + \"\\t\" + str(missing_percents[i]))\n",
    "output.close()\n",
    "\n",
    "print \"Samples have been written to an output file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\t\tcolumn\n",
      "JB121807_04.1 \t132\n",
      "JB121807_05 \t133\n",
      "JB121807_07.1 \t135\n",
      "JB121807_09.1 \t138\n",
      "JB121807_12.1 \t140\n",
      "JB121807_16.1 \t142\n",
      "JB121807_23 \t146\n",
      "JB121807_25 \t148\n",
      "JB121807_27 \t149\n",
      "JB121807_30 \t151\n",
      "JB121807_30.1 \t152\n",
      "JB121807_35 \t157\n",
      "JB121807_41.1 \t160\n",
      "JB121807_45.1 \t163\n",
      "JB121807_47 \t165\n",
      "JB121807_48.1 \t166\n",
      "JB021108_10.1 \t175\n",
      "JB021108_11 \t176\n",
      "JB021108_14 \t179\n",
      "JB021108_25.1 \t185\n",
      "JB021108_28 \t187\n",
      "JB021108_31.1 \t190\n",
      "JB021108_33 \t192\n",
      "JB021108_38.1 \t200\n",
      "JB021108_40 \t202\n",
      "BOR07_01 \t210\n",
      "BOR07_21.1 \t230\n",
      "GEO020414_10 \t232\n",
      "GEO020414_13 \t235\n",
      "GEO020414_30 \t256\n"
     ]
    }
   ],
   "source": [
    "print \"sample\\t\\tcolumn\"\n",
    "for i in range(0,len(column_numbers)):\n",
    "    print samples_missing_data[i], \"\\t\", column_numbers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
